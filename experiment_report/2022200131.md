《人工智能导论》大作业报告
一、实验名称
基于LSTM—Transformer混合模型的图像字幕生成
二、选题背景
1、项目简介
该图像字幕生成系统集成了图像处理和自然语言处理技术，旨在为用户提供高效、准确的图像与文本标注服务。该系统结合了图像识别、文本分析和机器学习等多种技术，能够同时处理图像和与之相关的文本信息，从而实现对图片内容的理解和标注。
2、主要功能
系统能够自动识别图像中的物体、场景、人物等关键元素，提取信息进行语义描述，帮助用户更好地理解图片内容。同时系统提供用户操作实践，方便用户进行交互并得到反馈。
3、应用场景
初始系统提供基本功能，若对于技术优化后的图像字幕生成系统则应用广泛：在计算机视觉与自然语言处理方面，可用于图像分类、物体检测等任务的数据标注;在多媒体内容管理方面，可用于社交媒体、电商平台等的图像和文本内容管理;在医疗领域，可用于对医学影像的分析，辅助治疗等，以及其他应用场景
三、数据处理
1、数据集选取
本系统选取数据集flickr-30k进行训练，共31783张图片，包含了丰富多样的真实场景图片，涵盖了人物、动物、风景、物体、事件等各种类别，具有很高的多样性和复杂性，能够很好地模拟现实世界中的图像场景。每张图片对应5句不同的英文描述语句，共计158915条语言描述，旨在从不同角度描述图像的内容、动作、场景等信息。（其中图片集以文件夹格式、描述文本以CSV文件格式给出）
2、数据预处理
（1）将初始数据整合成字典型数据，格式为【图片：含有五个语义描述的字符串数组】
（2）对于描述中字符个数少于4或者多于24的语句，将该语句所属字典剔除
（3）删除语句中不必要的字符（如：“\*），加上首尾标识字符“<start>”和“<end>”
（4）将80%的数据集作为训练集，剩余部分按照10:1的比例划分为验证集和测试集，最终得到处理好的数据


（5）将所有处理完后的描述语句单独整合到字符串数组text_data中，对其进行常规统计,得到语句的长度分布情况和前20个最常见单词的出现频率：


四、模型思路
1、特征提取
本项目主要基于EfficientNet-B0模型进行图像特征提取，其主要架构为拓展层、深度可分离卷积层、投影层。其中拓展层对输入图片进行逐点卷积，对特征图进行拓展；深度可分离卷积层进行空间卷积和通道混合，通过对每个输入通道单独进行卷积操作来显著减少参数数量；投影层逐点卷积，进行降维，与残差连接匹配。其关键设计理念中的复合缩放（使用统一的缩放因子平衡深度、宽度和输入分辨率），高效的基于移动网络的架构以及灵活的自适应调整实现了在计算资源受限的情况下仍然能够保持高效且高性能的图像特征提取。
2、模型训练
采用LSTM—Transformer混合模型：借助Transformer模型的编码器模块（包含自注意力机制和前馈网络）处理输入的图像特征序列，并输出编码后的序列；而后向输入序列添加位置编码。在Transformer模型中，位置编码帮助模型理解输入序列中单词的顺序，通过结合词汇嵌入和位置嵌入提供位置感知能力；最后通过融合了LSTM长短期记忆网络的Transformer解码器处理序列数据及长距离依赖，增强对语法结构和语义关系的理解能力。
3、细节优化
（1）稀疏分类交叉熵损失：衡量模型预测的概率分布与实际标签的概率分布之间的差异
（2）早停条件：当验证集上的损失在连续3个epoch中没有改善时，训练将停止
（3）Adam优化器：根掘梯度信息来更新神经网络参数，从而最小化损失函数
（4）余弦退火重启学习率调度器：通过余弦函数来降低学习率。
4、生成描述
编码器从图像中提取的特征被转换为嵌入向量，这些向量包含了图像的关键信息，并用于指导解码器生成文本；在生成标题的过程中，解码器会逐步构建文本，每次处理一个字符（一个时间步）。在生成下一个单词时，解码器还会考虑之前已经生成的单词，这通常是通过将之前生成的单词嵌入到向量空间中，并与图像特征相结合来实现的。而后基于图像特征和已生成的标题，解码器会计算下一个可能单词的概率分布，并选择最可能的单词作为输出。

贪心算法：在每个时间步，贪心算法都会从解码器输出的概率分布中选择概率最高的单词。这个单词被添加到已生成的标题中，然后解码器继续处理下一个时间步。这个过程会一直持续到解码器输出<end>标记或标题的长度达到预设的最大序列长度。
束搜索：通过迭代生成从预测的概率分布中选择概率最高的 beam_size个单词(即扩展当前的束)，并更新每个新候选描述的概率；而后进行排序剪枝，根据概率对新的候选描述集合进行排序，并选择概率最高的 beam_size个候选描述作为下一步输入。最后选择概率最高的描述作为最终输出。
五、结果展示
1、训练结果
设置参数epoch=20，batch_size=512，train_dataset的总长度为20982，即一轮有41批次

（由于早停机制，训练17轮停止）
2、损失函数
将训练集和验证集的损失函数可视化

3、评价指标
BLEU_Score 旨在计算给定预测描述( predicted)相对于一组实际描述(actual )的BLEU分数，是一种常用的机器翻译和图像描述生成等领域的质量评估指标，它衡量生成文本与参考文本之间的n-gram(n元组)匹配程度，同时考虑了简洁性惩罚。
METEOR 是一种用于评估机器翻译质量的自动度量，它通过考虑词汇的对齐和对齐词汇之间的顺序关系来评估生成的描述与参考描述之间的相似度。它不仅考虑了单词的匹配，还考虑了单词的顺序和结构，这在很多情况下比单纯的BLEU分数更能反映描述的质量。
综合以上两个指标进行赋权，得到综合的评价分数：

4、数据测试
模仿用户操作，上传图片以得到描述反馈


六、总结反思
在本项目中，我结合长短期记忆网络的处理序列数据的优势以及Transformer的自注意力机制全局上下文捕捉的能力，训练出图像字幕生成模型，并利用相关指标对其评价。但回顾构建过程，仍有许多不足之处：可改进LSTM，使用双层LETM，通过更深的网络层次完善模型的表达；对于图像特征提取的质量、词向量的准确性以及模型训练的超参数设置同样可以进一步优化；训练该混合模型需要大量计算资源，可考虑能否通过优化来节省计算成本。总之通过本次动手实现此项目，我学到了许多，深知自己仍需努力，我也会更为专注认真，加强本领，提升自我。
